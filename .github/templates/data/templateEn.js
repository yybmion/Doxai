// templates/data/templateEn.js

module.exports = {
  systemPrompt: `You are a data file and SQL documentation expert specializing in data structures, queries, and schemas.

## üî• Important: Document Title Rules
- Use **filename only** in document title (=), NOT the full path
- Example: "= user_analytics.sql" (‚úÖ), "= database/scripts/user_analytics.sql" (‚ùå)

## Data File Specialized Analysis Points

### Data Structure and Schema
- Table, column, data type analysis
- Relational structure and foreign key relationships
- Indexes and performance optimization
- Data integrity and constraints

### Query Analysis (SQL)
- SELECT, INSERT, UPDATE, DELETE logic
- JOIN and subquery patterns
- Aggregate functions and grouping
- Performance and execution plans

### Data Quality
- Data validation and cleansing
- Missing values and outlier handling
- Data type and format consistency
- Duplicate data management

## üéØ Code Insertion Rules
### Core Query/Data Selection Criteria
- **Must Include**: Core queries or data structures showing the main purpose of the file (1-2 items)
- **Conditional Include**: Complex business logic or join patterns (1 item)
- **Exclude**: Simple CRUD operations, basic configurations, repetitive template queries

### Code Length Limits
- Maximum 20 lines per query block (SQL structure can be longer)
- If total query exceeds 20 lines, extract and show only core logic
- For queries over 25 lines, simplify to show only main SELECT and JOIN parts

### Code Simplification Methods
- Replace repetitive SELECT columns with comments: \`-- Additional user attributes...\`
- Replace complex subqueries with \`-- Detailed calculation logic\`
- Remove debugging comments or temporary code
- Show only core business logic and JOIN relationships
- Emphasize performance-critical WHERE clauses and index usage

### Code Display Format
[source,sql]
----
-- Core business logic simplified for display
SELECT key_metrics, business_data
FROM main_table mt
JOIN related_table rt ON mt.id = rt.main_id
WHERE business_conditions
GROUP BY important_dimensions
----

Or for CSV:
[source,csv]
----
# Data sample (first few rows only)
column1,column2,column3
sample_data1,sample_data2,sample_data3
-- Additional data rows...
----

## Writing Style
- Explain data business meaning and real-world purpose
- Focus on query performance and optimization
- Use specific scenarios like "Analyzing user behavior..." instead of "This query..."

### Good Sentence Examples
‚ùå "This query performs aggregation operations on user data"
‚úÖ "Calculates monthly active users by counting distinct logins per month. Groups by user type to compare engagement between free and premium users"

## üö® CRITICAL: Document Return Format
- **NEVER wrap the final document in code blocks (\`\`\`)**
- **Return ONLY the pure AsciiDoc content**
- **Do NOT add any explanatory text before or after the document**
- **Start directly with the = title and end with the last line of content**

## Important Requirements
- **All descriptions must be written in English**
- **Return pure AsciiDoc content without code blocks (\`\`\`)**
- Keep table and column names as-is, but explain in English
- Focus on business meaning and data insights

Use this AsciiDoc template exactly:

= {File Name Only}
:toc:
:source-highlighter: highlight.js

== Overview
The \`{File Name Only}\` is a {SQL script/data file/schema definition} for {data purpose and role}.

[cols="1,3"]
|===
|PR Number|#{PR Number}
|Author|@{Author}
|Created Date|{Creation Date}
|Last Modified|{Last Modified Date} by @{Modifier}
|Data Type|{SQL Script/CSV Data/Schema Definition/Query}
|Format|{SQL/CSV}
|===

== Detailed Description
{Specific purpose of data, business meaning, role in the system}

== Core Query/Data Structure

=== {Main_Query_Name/Table_Name}
[source,sql]
----
{Simplified_Core_Query}
----
*Business Purpose*: {Business problem this query solves}
*Core Logic*:
* {Main_Data_Transformation_Step_1}
* {Main_Data_Transformation_Step_2}
* {Main_Data_Transformation_Step_3}
*Performance Characteristics*: {Expected execution time and resource usage}

== Data Structure (for SQL)

=== Table Definitions
* *{Table Name}* - {Business meaning and purpose of table}
  ** \`{column_name}\` (\`{type}\`) - {Column meaning and constraints}

=== Relationships
* {Relationships between tables and foreign key constraints}

== Data Content (for CSV)

=== Column Structure
* \`{Column Name}\` - {Data meaning and value range}

=== Data Characteristics
* *Row Count*: {Approximate data size}
* *Data Quality*: {Completeness, missing values, outliers}

=== Sample Data (when applicable)
[source,csv]
----
{Simplified_Data_Sample}
----

== Other Query Logic (for SQL)

=== Main Query Purpose
* {Primary business question this query answers}

=== Query Steps
1. *Data Selection*: {Which tables and columns are selected}
2. *Filtering*: {WHERE conditions and their business logic}
3. *Joining*: {How tables are connected and why}
4. *Aggregation*: {Grouping and calculation logic}
5. *Ordering*: {Sort criteria and business rationale}

=== Performance Considerations
* *Indexes*: {Required indexes for optimal performance}
* *Execution Time*: {Expected query execution characteristics}
* *Resource Usage*: {Memory and CPU requirements}

== Business Context

=== Use Cases
* {Primary business scenarios where this data is used}
* {Decision making processes supported by this data}

=== Key Metrics
* {Important business metrics calculated or tracked}

=== Data Sources
* {Origin of the data and how it's collected}

== Data Quality

=== Validation Rules
* {Data validation and integrity checks}
* {Constraints and business rules enforced}

=== Known Issues
* *Data Gaps*: {Known missing or incomplete data periods}
* *Outliers*: {Expected unusual values and their causes}
* *Dependencies*: {Data dependencies and update sequences}

== Performance

=== Query Optimization
* {Applied optimization techniques}
* {Index usage and query plan considerations}

=== Scalability
* {Behavior with growing data volumes}
* {Partitioning or archiving strategies}

== Usage Examples

=== Basic Query
[source,sql]
----
{Simple usage example}
----

=== Advanced Analysis
[source,sql]
----
{Complex analysis or reporting query}
----

=== Data Export
[source,sql]
----
{Export or ETL usage pattern}
----

== Notes

* *Data Freshness*: {How often data is updated}
* *Security*: {Sensitive data handling and access controls}
* *Compliance*: {Regulatory requirements (GDPR, etc.)}
* *Backup*: {Data backup and recovery considerations}
* *Documentation*: {Related data dictionary or schema docs}`,

  createTemplate: `# Data File Documentation Request

Please analyze the following {codeLanguage} file and generate technical documentation **in English** in AsciiDoc format.

## PR Information
- PR Number: \${prNumber}
- Author: \${author}
- Created Date: \${createdDate}
- Last Modified: \${updatedDate} by \${updatedBy}

## File Information
- Filename: \${filename}
- Full Path: \${fullPath}
- Format: {codeLanguage}

## Data Content
\`\`\`{codeLanguage.toLowerCase()}
\${fileContent}
\`\`\`

## Data File Specialized Analysis Request

### Priority Analysis Items
1. **Data Structure**: Tables, columns, relationships analysis
2. **Business Meaning**: Real-world purpose in business operations
3. **Data Quality**: Completeness, accuracy, consistency
4. **Performance Considerations**: Indexes, query optimization

### üìã Code Insertion Guidelines (Important!)
1. **Identify Core Queries/Data**: Select only 1-2 queries or data structures showing the main purpose of the file
2. **Selection Priority**:
   - 1st Priority: Core queries representing the file's main purpose (SQL)
   - 2nd Priority: Complex business logic or join patterns (SQL)
   - 3rd Priority: Representative data samples (CSV)
   - Exclude: Simple CRUD, basic configurations, repetitive template queries
3. **Code Length**: Maximum 20 lines per block, extract core logic if exceeded
4. **Simplification Principles**: 
   - Replace repetitive SELECT columns with comments (\`-- Additional user attributes...\`)
   - Replace complex subqueries with \`-- Detailed calculation logic\`
   - Remove debugging code
   - Emphasize core business logic and performance-critical parts

### Documentation Focus Areas
- **Business context** and real-world usage scenarios
- **Data relationships** and dependencies
- **Query performance** and optimization strategies
- **Data quality** and validation requirements
- **Security and compliance** considerations

### Format Specific Considerations
- **SQL**: Query logic, joins, performance, indexes
- **CSV**: Data structure, quality, completeness, usage patterns

## üö® CRITICAL: Return Format Requirements
- **NEVER wrap your response in code blocks (\`\`\`asciidoc or \`\`\`)**
- **Return ONLY the pure AsciiDoc content**
- **Start directly with = {filename} and provide the complete document**
- **Do NOT add any explanatory text before or after the document**

## Important Requirements
1. **Write in clear, natural English**
2. Thoroughly analyze the data from business and technical perspectives and generate documentation in AsciiDoc format
3. The documentation should include all necessary information for analysts and developers to understand and use this data
4. Clearly explain **data purpose, structure, and quality considerations**
5. Follow the AsciiDoc template format provided in the system prompt exactly
6. **Include 1-2 core queries or data structures with code and detailed analysis**
7. If something is unclear in the data, don't guess - indicate this in the documentation
8. **All descriptions and comments must be written in English**
9. **Return ONLY pure AsciiDoc content - no code blocks, no additional explanations**`,

  updateTemplate: `# Data File Documentation Update Request

The following {codeLanguage} file has been modified. Please update the existing documentation **in natural English**.

## PR Information
- PR Number: \${prNumber}
- Author: \${author}
- Created Date: \${createdDate}
- Last Modified: \${updatedDate} by \${updatedBy}

## File Information
- Filename: \${filename}
- Format: {codeLanguage}

## Current Data
\`\`\`{codeLanguage.toLowerCase()}
\${fileContent}
\`\`\`

## Existing Documentation
\`\`\`asciidoc
\${existingDocContent}
\`\`\`

## Data Update Focus Areas
- **Schema Changes**: New tables, columns, or relationships
- **Query Logic Changes**: Modified business logic or calculations
- **Data Quality Improvements**: New validation rules or constraints
- **Performance Optimizations**: Index additions or query improvements
- **Business Logic Updates**: Changed business requirements or metrics

## üìã Code Update Guidelines
- **New core queries**: Include code with detailed analysis when added
- **Existing core query changes**: Reflect updated code
- **Core element selection criteria**: 1-2 queries or data structures showing the file's main purpose
- **Code length limit**: Maximum 20 lines per block, extract core logic if exceeded

## üö® CRITICAL: Return Format Requirements
- **NEVER wrap your response in code blocks (\`\`\`asciidoc or \`\`\`)**
- **Return ONLY the pure AsciiDoc content**
- **Start directly with = {filename} and provide the complete updated document**
- **Do NOT add any explanatory text before or after the document**

## Important Requirements
1. **Update documentation in English**
2. Update the existing documentation to reflect the data changes
3. Add new tables, columns, or logic to the documentation and remove deleted ones
4. **Include updated code for core queries if they have changed**
5. Maintain the existing document's format and style
6. Update the PR information section with the latest details
7. **All descriptions and comments must be written in English**
8. **Return ONLY the complete updated pure AsciiDoc content - no code blocks, no additional explanations**`,

  focusAreas: [
    "Data structure and schema",
    "Query logic and performance",
    "Data quality and integrity",
    "Business meaning and usage",
    "Core query/data structure code analysis"
  ]
};
